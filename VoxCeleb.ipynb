{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Reshape\n",
    "from keras.layers.convolutional import Conv2D, ZeroPadding2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Lambda, Activation\n",
    "from keras.models import Model\n",
    "import decimal\n",
    "import numpy\n",
    "import math\n",
    "import logging\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist, euclidean, cosine\n",
    "from glob import glob\n",
    "from scipy.signal import lfilter, butter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training and Testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['./wav_id10270/PXmaB6Ui0fE/00001.wav',\n",
    "             './wav_id10270/zjwijMp0Qyw/00001.wav',\n",
    "             './wav_id10270/zjwijMp0Qyw/00002.wav',\n",
    "             './wav_id10270/zjwijMp0Qyw/00003.wav',\n",
    "             './wav_id10270/OmSWVqpb-N0/00001.wav',\n",
    "             \n",
    "             \n",
    "            './wav_id10271/gO805KoL2RM/00001.wav',\n",
    "             './wav_id10271/gO805KoL2RM/00002.wav',\n",
    "             './wav_id10271/gO805KoL2RM/00003.wav',\n",
    "             './wav_id10271/gO805KoL2RM/00004.wav',\n",
    "             './wav_id10271/gO805KoL2RM/00005.wav',\n",
    "             './wav_id10271/gO805KoL2RM/00006.wav',\n",
    "             './wav_id10271/gO805KoL2RM/00007.wav',\n",
    "            ]\n",
    "\n",
    "\n",
    "speakers = [\n",
    "    10270,\n",
    "    10270,\n",
    "    10270,\n",
    "    10270,\n",
    "    10270,\n",
    "    \n",
    "    \n",
    "    10271,\n",
    "    10271,\n",
    "    10271,\n",
    "    10271,\n",
    "    10271,\n",
    "    10271,\n",
    "    10271,\n",
    "    \n",
    "]\n",
    "\n",
    "data = pd.DataFrame(data = np.column_stack([filenames, speakers]) ,columns=['filename', 'speaker'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data.speaker, test_size=0.33, random_state=42, stratify=data.speaker)\n",
    "X_train.to_csv('train.csv', index=False)\n",
    "X_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "PREEMPHASIS_ALPHA = 0.97\n",
    "FRAME_LEN = 0.025\n",
    "FRAME_STEP = 0.01\n",
    "NUM_FFT = 512\n",
    "BUCKET_STEP = 1\n",
    "MAX_SEC = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COST_METRIC = \"cosine\"  # euclidean or cosine\n",
    "INPUT_SHAPE=(NUM_FFT,None,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENROLL_LIST_FILE = \"./train.csv\"\n",
    "TEST_LIST_FILE = \"./test.csv\"\n",
    "RESULT_FILE = \"./results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = 'weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_pool(inp_tensor,layer_idx,conv_filters,conv_kernel_size,conv_strides,conv_pad,\n",
    "    pool='',pool_size=(2, 2),pool_strides=None,\n",
    "    conv_layer_prefix='conv'):\n",
    "    x = ZeroPadding2D(padding=conv_pad,name='pad{}'.format(layer_idx))(inp_tensor)\n",
    "    x = Conv2D(filters=conv_filters,kernel_size=conv_kernel_size, strides=conv_strides, padding='valid', name='{}{}'.format(conv_layer_prefix,layer_idx))(x)\n",
    "    x = BatchNormalization(epsilon=1e-5,momentum=1,name='bn{}'.format(layer_idx))(x)\n",
    "    x = Activation('relu', name='relu{}'.format(layer_idx))(x)\n",
    "    if pool == 'max':\n",
    "        x = MaxPooling2D(pool_size=pool_size,strides=pool_strides,name='mpool{}'.format(layer_idx))(x)\n",
    "    elif pool == 'avg':\n",
    "        x = AveragePooling2D(pool_size=pool_size,strides=pool_strides,name='apool{}'.format(layer_idx))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_bn_dynamic_apool(inp_tensor,layer_idx,conv_filters,conv_kernel_size,conv_strides,conv_pad,\n",
    "    conv_layer_prefix='conv'):\n",
    "    x = ZeroPadding2D(padding=conv_pad,name='pad{}'.format(layer_idx))(inp_tensor)\n",
    "    x = Conv2D(filters=conv_filters,kernel_size=conv_kernel_size, strides=conv_strides, padding='valid', name='{}{}'.format(conv_layer_prefix,layer_idx))(x)\n",
    "    x = BatchNormalization(epsilon=1e-5,momentum=1,name='bn{}'.format(layer_idx))(x)\n",
    "    x = Activation('relu', name='relu{}'.format(layer_idx))(x)\n",
    "    x = GlobalAveragePooling2D(name='gapool{}'.format(layer_idx))(x)\n",
    "    x = Reshape((1,1,conv_filters),name='reshape{}'.format(layer_idx))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def vggvox_model():\n",
    "    inp = Input(INPUT_SHAPE,name='input')\n",
    "    x = conv_bn_pool(inp,layer_idx=1,conv_filters=96,conv_kernel_size=(7,7),conv_strides=(2,2),conv_pad=(1,1),\n",
    "        pool='max',pool_size=(3,3),pool_strides=(2,2))\n",
    "    x = conv_bn_pool(x,layer_idx=2,conv_filters=256,conv_kernel_size=(5,5),conv_strides=(2,2),conv_pad=(1,1),\n",
    "        pool='max',pool_size=(3,3),pool_strides=(2,2))\n",
    "    x = conv_bn_pool(x,layer_idx=3,conv_filters=384,conv_kernel_size=(3,3),conv_strides=(1,1),conv_pad=(1,1))\n",
    "    x = conv_bn_pool(x,layer_idx=4,conv_filters=256,conv_kernel_size=(3,3),conv_strides=(1,1),conv_pad=(1,1))\n",
    "    x = conv_bn_pool(x,layer_idx=5,conv_filters=256,conv_kernel_size=(3,3),conv_strides=(1,1),conv_pad=(1,1),\n",
    "        pool='max',pool_size=(5,3),pool_strides=(3,2))\t\t\n",
    "    x = conv_bn_dynamic_apool(x,layer_idx=6,conv_filters=4096,conv_kernel_size=(9,1),conv_strides=(1,1),conv_pad=(0,0),\n",
    "        conv_layer_prefix='fc')\n",
    "    x = conv_bn_pool(x,layer_idx=7,conv_filters=1024,conv_kernel_size=(1,1),conv_strides=(1,1),conv_pad=(0,0),\n",
    "        conv_layer_prefix='fc')\n",
    "    x = Lambda(lambda y: K.l2_normalize(y, axis=3), name='norm')(x)\n",
    "    x = Conv2D(filters=1024,kernel_size=(1,1), strides=(1,1), padding='valid', name='fc8')(x)\n",
    "    m = Model(inp, x, name='VGGVox')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "def rolling_window(a, window, step=1):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::step]\n",
    "\n",
    "def framesig(sig, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,)), stride_trick=True):\n",
    "    slen = len(sig)\n",
    "    frame_len = int(round_half_up(frame_len))\n",
    "    frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step)) # LV\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "    zeros = numpy.zeros((padlen - slen,))\n",
    "    padsignal = numpy.concatenate((sig, zeros))\n",
    "    if stride_trick:\n",
    "        win = winfunc(frame_len)\n",
    "        frames = rolling_window(padsignal, window=frame_len, step=frame_step)\n",
    "    else:\n",
    "        indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "            numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "        indices = numpy.array(indices, dtype=numpy.int32)\n",
    "        frames = padsignal[indices]\n",
    "        win = numpy.tile(winfunc(frame_len), (numframes, 1))\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "def deframesig(frames, siglen, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,))):\n",
    "    frame_len = round_half_up(frame_len)\n",
    "    frame_step = round_half_up(frame_step)\n",
    "    numframes = numpy.shape(frames)[0]\n",
    "    assert numpy.shape(frames)[1] == frame_len, '\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "        numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "    indices = numpy.array(indices, dtype=numpy.int32)\n",
    "    padlen = (numframes - 1) * frame_step + frame_len\n",
    "\n",
    "    if siglen <= 0: siglen = padlen\n",
    "\n",
    "    rec_signal = numpy.zeros((padlen,))\n",
    "    window_correction = numpy.zeros((padlen,))\n",
    "    win = winfunc(frame_len)\n",
    "\n",
    "    for i in range(0, numframes):\n",
    "        window_correction[indices[i, :]] = window_correction[\n",
    "                                               indices[i, :]] + win + 1e-15  # add a little bit so it is never zero\n",
    "        rec_signal[indices[i, :]] = rec_signal[indices[i, :]] + frames[i, :]\n",
    "\n",
    "    rec_signal = rec_signal / window_correction\n",
    "    return rec_signal[0:siglen]\n",
    "\n",
    "def magspec(frames, NFFT):\n",
    "    if numpy.shape(frames)[1] > NFFT:\n",
    "        logging.warn(\n",
    "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
    "            numpy.shape(frames)[1], NFFT)\n",
    "    complex_spec = numpy.fft.rfft(frames, NFFT)\n",
    "    return numpy.absolute(complex_spec)\n",
    "\n",
    "def powspec(frames, NFFT):\n",
    "    return 1.0 / NFFT * numpy.square(magspec(frames, NFFT))\n",
    "\n",
    "def logpowspec(frames, NFFT, norm=1):\n",
    "    ps = powspec(frames, NFFT);\n",
    "    ps[ps <= 1e-30] = 1e-30\n",
    "    lps = 10 * numpy.log10(ps)\n",
    "    if norm:\n",
    "        return lps - numpy.max(lps)\n",
    "    else:\n",
    "        return lps\n",
    "\n",
    "def preemphasis(signal, coeff=0.95):\n",
    "    return numpy.append(signal[0], signal[1:] - coeff * signal[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading .wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(filename, sample_rate):\n",
    "    audio, sr = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "    audio = audio.flatten()\n",
    "    return audio\n",
    "\n",
    "def normalize_frames(m,epsilon=1e-12):\n",
    "    return np.array([(v - np.mean(v)) / max(np.std(v),epsilon) for v in m])\n",
    "\n",
    "def remove_dc_and_dither(sin, sample_rate):\n",
    "    if sample_rate == 16e3:\n",
    "        alpha = 0.99\n",
    "    elif sample_rate == 8e3:\n",
    "        alpha = 0.999\n",
    "    else:\n",
    "        print(\"Sample rate must be 16kHz or 8kHz only\")\n",
    "        exit(1)\n",
    "    sin = lfilter([1,-1], [1,-alpha], sin)\n",
    "    dither = np.random.random_sample(len(sin)) + np.random.random_sample(len(sin)) - 1\n",
    "    spow = np.std(dither)\n",
    "    sout = sin + 1e-6 * spow * dither\n",
    "    return sout\n",
    "\n",
    "\n",
    "def get_fft_spectrum(filename, buckets):\n",
    "    signal = load_wav(filename,SAMPLE_RATE)\n",
    "    signal *= 2**15\n",
    "\n",
    "    signal = remove_dc_and_dither(signal, SAMPLE_RATE)\n",
    "    signal = preemphasis(signal, coeff=PREEMPHASIS_ALPHA)\n",
    "    frames = framesig(signal, frame_len=FRAME_LEN*SAMPLE_RATE, frame_step=FRAME_STEP*SAMPLE_RATE, winfunc=np.hamming)\n",
    "    fft = abs(np.fft.fft(frames,n=NUM_FFT))\n",
    "    fft_norm = normalize_frames(fft.T)\n",
    "\n",
    "    rsize = max(k for k in buckets if k <= fft_norm.shape[1])\n",
    "    rstart = int((fft_norm.shape[1]-rsize)/2)\n",
    "    out = fft_norm[:,rstart:rstart+rsize]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_buckets(max_sec, step_sec, frame_step):\n",
    "    buckets = {}\n",
    "    frames_per_sec = int(1/frame_step)\n",
    "    end_frame = int(max_sec*frames_per_sec)\n",
    "    step_frame = int(step_sec*frames_per_sec)\n",
    "    for i in range(0, end_frame+1, step_frame):\n",
    "        s = i\n",
    "        s = np.floor((s-7+2)/2) + 1  # conv1\n",
    "        s = np.floor((s-3)/2) + 1  # mpool1\n",
    "        s = np.floor((s-5+2)/2) + 1  # conv2\n",
    "        s = np.floor((s-3)/2) + 1  # mpool2\n",
    "        s = np.floor((s-3+2)/1) + 1  # conv3\n",
    "        s = np.floor((s-3+2)/1) + 1  # conv4\n",
    "        s = np.floor((s-3+2)/1) + 1  # conv5    enroll_result = get_embeddings_from_list_file(model, ENROLL_LIST_FILE, MAX_SEC)\n",
    "\n",
    "        s = np.floor((s-3)/2) + 1  # mpool5\n",
    "        s = np.floor((s-1)/1) + 1  # fc6\n",
    "        if s > 0:\n",
    "            buckets[i] = int(s)\n",
    "    return buckets\n",
    "\n",
    "def get_embeddings_from_list_file(model, list_file, max_sec):\n",
    "    buckets = build_buckets(max_sec, BUCKET_STEP, FRAME_STEP)\n",
    "    result = pd.read_csv(list_file, delimiter=\",\")\n",
    "    result['features'] = result['filename'].apply(lambda x: get_fft_spectrum(x, buckets))\n",
    "    result['embedding'] = result['features'].apply(lambda x: np.squeeze(model.predict(x.reshape(1,*x.shape,1))))\n",
    "    return result[['filename','speaker','embedding']]\n",
    "\n",
    "def get_id_result():\n",
    "    print(\"Loading model weights from [{}]....\".format(WEIGHTS_FILE))\n",
    "    model = vggvox_model()\n",
    "    model.load_weights(WEIGHTS_FILE)\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Processing enroll samples....\")\n",
    "    enroll_result = get_embeddings_from_list_file(model, ENROLL_LIST_FILE, MAX_SEC)\n",
    "    enroll_embs = np.array([emb.tolist() for emb in enroll_result['embedding']])\n",
    "    speakers = enroll_result['speaker']\n",
    "\n",
    "    print(\"Processing test samples....\")\n",
    "    test_result = get_embeddings_from_list_file(model, TEST_LIST_FILE, MAX_SEC)\n",
    "    test_embs = np.array([emb.tolist() for emb in test_result['embedding']])\n",
    "\n",
    "    print(\"Comparing test samples against enroll samples....\")\n",
    "    distances = pd.DataFrame(cdist(test_embs, enroll_embs, metric=COST_METRIC), columns=speakers)\n",
    "\n",
    "    scores = pd.read_csv(TEST_LIST_FILE, delimiter=\",\",header=0,names=['test_file','test_speaker'])\n",
    "    scores = pd.concat([scores, distances],axis=1)\n",
    "    scores['result'] = scores[speakers].idxmin(axis=1)\n",
    "    scores['correct'] = (scores['result'] == scores['test_speaker'])*1. # bool to int\n",
    "\n",
    "    print(\"Writing outputs to [{}]....\".format(RESULT_FILE))\n",
    "    with open(RESULT_FILE, 'w') as f:\n",
    "        scores.to_csv(f, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/salman/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = vggvox_model()\n",
    "model.load_weights(WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>speaker</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./wav_id10271/gO805KoL2RM/00003.wav</td>\n",
       "      <td>10271</td>\n",
       "      <td>[[0.4049732967976058, -0.21972975748477772, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./wav_id10271/gO805KoL2RM/00004.wav</td>\n",
       "      <td>10271</td>\n",
       "      <td>[[-0.8736938721405686, -0.7912838823148415, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./wav_id10270/zjwijMp0Qyw/00001.wav</td>\n",
       "      <td>10270</td>\n",
       "      <td>[[4.217089959875128, -0.7909704015488229, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./wav_id10270/OmSWVqpb-N0/00001.wav</td>\n",
       "      <td>10270</td>\n",
       "      <td>[[-0.8215791340452662, 0.5318020175808723, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./wav_id10271/gO805KoL2RM/00002.wav</td>\n",
       "      <td>10271</td>\n",
       "      <td>[[-0.1216659165698467, 2.9765601247144655, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  speaker  \\\n",
       "0  ./wav_id10271/gO805KoL2RM/00003.wav    10271   \n",
       "1  ./wav_id10271/gO805KoL2RM/00004.wav    10271   \n",
       "2  ./wav_id10270/zjwijMp0Qyw/00001.wav    10270   \n",
       "3  ./wav_id10270/OmSWVqpb-N0/00001.wav    10270   \n",
       "4  ./wav_id10271/gO805KoL2RM/00002.wav    10271   \n",
       "\n",
       "                                            features  \n",
       "0  [[0.4049732967976058, -0.21972975748477772, -0...  \n",
       "1  [[-0.8736938721405686, -0.7912838823148415, 0....  \n",
       "2  [[4.217089959875128, -0.7909704015488229, -0.1...  \n",
       "3  [[-0.8215791340452662, 0.5318020175808723, 0.0...  \n",
       "4  [[-0.1216659165698467, 2.9765601247144655, -0....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = build_buckets(MAX_SEC, BUCKET_STEP, FRAME_STEP)\n",
    "data = pd.read_csv(ENROLL_LIST_FILE, delimiter=\",\")\n",
    "data['features'] = data['filename'].apply(lambda x: get_fft_spectrum(x, buckets))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = data.features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = []\n",
    "for each in feats:\n",
    "    data_train.append(each.reshape(1,*each.shape,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for each in feats:\n",
    "    x = each.flatten()\n",
    "    x = x.tolist()\n",
    "    x = x[0:1024]\n",
    "    x = np.array(x)\n",
    "    y_train.append(x.reshape(1,1,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    k = 0\n",
    "    while True:\n",
    "        if k >= len(data_train) or k >= len(y_train):\n",
    "            k = 0\n",
    "        yield (data_train[k], [[y_train[k]]])\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 7s 936ms/step - loss: 0.6826\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 9s 1s/step - loss: 0.6711\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.6649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc312430e48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch=int(len(data_train)), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights from [weights.h5]....\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 512, None, 1)      0         \n",
      "_________________________________________________________________\n",
      "pad1 (ZeroPadding2D)         (None, 514, None, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 254, None, 96)     4800      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 254, None, 96)     384       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 254, None, 96)     0         \n",
      "_________________________________________________________________\n",
      "mpool1 (MaxPooling2D)        (None, 126, None, 96)     0         \n",
      "_________________________________________________________________\n",
      "pad2 (ZeroPadding2D)         (None, 128, None, 96)     0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 62, None, 256)     614656    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 62, None, 256)     1024      \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 62, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "mpool2 (MaxPooling2D)        (None, 30, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "pad3 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 30, None, 384)     885120    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 30, None, 384)     1536      \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 30, None, 384)     0         \n",
      "_________________________________________________________________\n",
      "pad4 (ZeroPadding2D)         (None, 32, None, 384)     0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 30, None, 256)     884992    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 30, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "pad5 (ZeroPadding2D)         (None, 32, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 30, None, 256)     590080    \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 30, None, 256)     1024      \n",
      "_________________________________________________________________\n",
      "relu5 (Activation)           (None, 30, None, 256)     0         \n",
      "_________________________________________________________________\n",
      "mpool5 (MaxPooling2D)        (None, 9, None, 256)      0         \n",
      "_________________________________________________________________\n",
      "pad6 (ZeroPadding2D)         (None, 9, None, 256)      0         \n",
      "_________________________________________________________________\n",
      "fc6 (Conv2D)                 (None, 1, None, 4096)     9441280   \n",
      "_________________________________________________________________\n",
      "bn6 (BatchNormalization)     (None, 1, None, 4096)     16384     \n",
      "_________________________________________________________________\n",
      "relu6 (Activation)           (None, 1, None, 4096)     0         \n",
      "_________________________________________________________________\n",
      "gapool6 (GlobalAveragePoolin (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape6 (Reshape)           (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "pad7 (ZeroPadding2D)         (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "fc7 (Conv2D)                 (None, 1, 1, 1024)        4195328   \n",
      "_________________________________________________________________\n",
      "bn7 (BatchNormalization)     (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "relu7 (Activation)           (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "norm (Lambda)                (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "fc8 (Conv2D)                 (None, 1, 1, 1024)        1049600   \n",
      "=================================================================\n",
      "Total params: 17,691,328\n",
      "Trainable params: 17,678,592\n",
      "Non-trainable params: 12,736\n",
      "_________________________________________________________________\n",
      "Processing enroll samples....\n",
      "Processing test samples....\n",
      "Comparing test samples against enroll samples....\n",
      "Writing outputs to [./results.csv]....\n"
     ]
    }
   ],
   "source": [
    "get_id_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('./results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_file</th>\n",
       "      <th>test_speaker</th>\n",
       "      <th>10271</th>\n",
       "      <th>10271.1</th>\n",
       "      <th>10270</th>\n",
       "      <th>10270.1</th>\n",
       "      <th>10271.2</th>\n",
       "      <th>10271.3</th>\n",
       "      <th>10271.4</th>\n",
       "      <th>10270.2</th>\n",
       "      <th>result</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./wav_id10270/PXmaB6Ui0fE/00001.wav</td>\n",
       "      <td>10270</td>\n",
       "      <td>1.137507</td>\n",
       "      <td>1.277028</td>\n",
       "      <td>0.533418</td>\n",
       "      <td>0.230680</td>\n",
       "      <td>1.068836</td>\n",
       "      <td>1.006705</td>\n",
       "      <td>1.117759</td>\n",
       "      <td>0.250231</td>\n",
       "      <td>10270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./wav_id10271/gO805KoL2RM/00007.wav</td>\n",
       "      <td>10271</td>\n",
       "      <td>0.241161</td>\n",
       "      <td>0.405256</td>\n",
       "      <td>1.508618</td>\n",
       "      <td>1.389528</td>\n",
       "      <td>0.335407</td>\n",
       "      <td>0.101641</td>\n",
       "      <td>0.299530</td>\n",
       "      <td>1.251152</td>\n",
       "      <td>10271</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./wav_id10270/zjwijMp0Qyw/00003.wav</td>\n",
       "      <td>10270</td>\n",
       "      <td>1.455477</td>\n",
       "      <td>1.446079</td>\n",
       "      <td>0.226746</td>\n",
       "      <td>0.125839</td>\n",
       "      <td>1.470072</td>\n",
       "      <td>1.232531</td>\n",
       "      <td>1.363944</td>\n",
       "      <td>0.095051</td>\n",
       "      <td>10270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./wav_id10271/gO805KoL2RM/00005.wav</td>\n",
       "      <td>10271</td>\n",
       "      <td>0.136283</td>\n",
       "      <td>0.236162</td>\n",
       "      <td>1.589197</td>\n",
       "      <td>1.370028</td>\n",
       "      <td>0.106838</td>\n",
       "      <td>0.334094</td>\n",
       "      <td>0.132241</td>\n",
       "      <td>1.336195</td>\n",
       "      <td>10271</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             test_file  test_speaker     10271   10271.1  \\\n",
       "0  ./wav_id10270/PXmaB6Ui0fE/00001.wav         10270  1.137507  1.277028   \n",
       "1  ./wav_id10271/gO805KoL2RM/00007.wav         10271  0.241161  0.405256   \n",
       "2  ./wav_id10270/zjwijMp0Qyw/00003.wav         10270  1.455477  1.446079   \n",
       "3  ./wav_id10271/gO805KoL2RM/00005.wav         10271  0.136283  0.236162   \n",
       "\n",
       "      10270   10270.1   10271.2   10271.3   10271.4   10270.2  result  correct  \n",
       "0  0.533418  0.230680  1.068836  1.006705  1.117759  0.250231   10270      1.0  \n",
       "1  1.508618  1.389528  0.335407  0.101641  0.299530  1.251152   10271      1.0  \n",
       "2  0.226746  0.125839  1.470072  1.232531  1.363944  0.095051   10270      1.0  \n",
       "3  1.589197  1.370028  0.106838  0.334094  0.132241  1.336195   10271      1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
